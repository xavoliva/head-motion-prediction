{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: Head position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create your first MLP in Keras\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy import interpolate\n",
    "from utils.convert_coord import equirect_to_cart, cart_to_equirect\n",
    "from utils.data_generator_seq2seq import data_generator_head_seq2seq_reinject_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random as rn\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate, CuDNNLSTM, \\\n",
    "    Conv1D, MaxPooling1D, Flatten, TimeDistributed, Reshape, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from attention_keras.layers.attention import AttentionLayer\n",
    "\n",
    "## reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "# fix random seed for reproducibility\n",
    "seed = 7 #42\n",
    "np.random.seed(seed)\n",
    "# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "rn.seed(12345)\n",
    "# Force TensorFlow to use single thread. Multiple threads are a potential source of non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# The below tf.set_random_seed() will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "tf.set_random_seed(1234)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "print(\"python: {}, keras: {}, tensorflow: {}\".format(sys.version, keras.__version__, tf.__version__))\n",
    "\n",
    "dir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'final_seq2seq_decoder_reinject_output_attention_3-128'\n",
    "\n",
    "time_step = 10 # 10 ms\n",
    "lookback = 250 # 250 ms\n",
    "n_lookback = int(round(lookback / time_step))\n",
    "\n",
    "step_delay = 100\n",
    "n_delay = int(round(step_delay / time_step))\n",
    "delays_list = list(range(100, 1000+1, step_delay))\n",
    "n_max_delay = int(round(np.max(delays_list) / time_step))\n",
    "\n",
    "len_delay = len(delays_list)\n",
    "\n",
    "# HARD CODED MAXIMUM DIFFERENCES\n",
    "MAX_DIFF = np.array([1.95763439, 0.06364631, 1.99985595])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# create model\n",
    "encoder_inputs = Input(shape=(n_lookback, 3))\n",
    "latent_dim = 128 # LSTM hidden units\n",
    "\n",
    "# Define an input series and encode it with an LSTM.\n",
    "encoder_1, h1, c1 = CuDNNLSTM(units=latent_dim, return_state=True, return_sequences=True)(encoder_inputs)\n",
    "encoder_2, h2, c2 = CuDNNLSTM(units=latent_dim, return_state=True, return_sequences=True)(encoder_1)\n",
    "encoder_3, h3, c3 = CuDNNLSTM(units=latent_dim, return_state=True, return_sequences=True)(encoder_2)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the final states. These represent the \"context\"\n",
    "# vector that we use as the basis for decoding.\n",
    "encoder_states = [h1, c1, h2, c2, h3, c3]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "# This is where teacher forcing inputs are fed in.\n",
    "decoder_input = Input(shape=(1, 3)) \n",
    "\n",
    "decoder_1 = CuDNNLSTM(units=latent_dim, return_state=True, return_sequences=True)\n",
    "decoder_2 = CuDNNLSTM(units=latent_dim, return_state=True, return_sequences=True)\n",
    "decoder_3 = CuDNNLSTM(units=latent_dim, return_state=True, return_sequences=True)\n",
    "\n",
    "dense_1 = TimeDistributed(Dense(latent_dim, activation=\"relu\"))\n",
    "dense_2 = TimeDistributed(Dense(3))\n",
    "\n",
    "dense_3 = TimeDistributed(Dense(latent_dim, activation=\"relu\"))\n",
    "dense_4 = TimeDistributed(Dense(3))\n",
    "\n",
    "# We set up our decoder using `encoder_states` as initial state.  \n",
    "# We return full output sequences and return internal states as well. \n",
    "# We don't use the return states in the training model, but we will use them in inference.\n",
    "\n",
    "all_outputs = []\n",
    "inputs = decoder_input\n",
    "states = encoder_states\n",
    "\n",
    "for _ in range(len_delay):\n",
    "\n",
    "    decoder_outputs_1, dh1, dc1 = decoder_1(inputs, initial_state=[states[0], states[1]])\n",
    "\n",
    "    decoder_outputs_2, dh2, dc2 = decoder_2(decoder_outputs_1, initial_state=[states[2], states[3]])\n",
    "\n",
    "    decoder_outputs_3, dh3, dc3 = decoder_3(decoder_outputs_2, initial_state=[states[4], states[5]])\n",
    "\n",
    "    outputs = dense_1(decoder_outputs_3)\n",
    "    # outputs = dense_2(dense_1_outputs)\n",
    "    \n",
    "    all_outputs.append(outputs)\n",
    "    \n",
    "    inputs = outputs\n",
    "    states = [dh1, dc1, dh2, dc2, dh3, dc3]\n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Lambda(lambda x: K.concatenate(x, axis=1))(all_outputs)\n",
    "\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_3, decoder_outputs])\n",
    "decoder_concat_input = Concatenate()([decoder_outputs, attn_out])\n",
    "\n",
    "dense_3_outputs = dense_3(decoder_concat_input)\n",
    "dense_4_outputs = dense_4(dense_3_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "print(decoder_outputs.shape)\n",
    "model = Model(inputs=[encoder_inputs, decoder_input], outputs=dense_4_outputs)\n",
    "\n",
    "\n",
    "# Compile model\n",
    "#adam = Adam(lr=0.01)\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 100 * K.mean(K.abs(y_pred - y_true) / (K.abs(y_true) + K.abs(y_pred)))\n",
    "\n",
    "def mfe(y_true, y_pred):\n",
    "    return K.mean(y_pred - y_true)\n",
    "\n",
    "model.compile(loss='mae', optimizer=\"adam\", metrics=[rmse, smape, mfe])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file=experiment_name+'.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = TensorBoard(log_dir='./tensorboard_logs',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=True,\n",
    "                                   write_grads=True,\n",
    "                                   write_images=True,\n",
    "                                   embeddings_freq=0,\n",
    "                                   embeddings_layer_names=None,\n",
    "                                   embeddings_metadata=None)\n",
    "\n",
    "earlystopping_callback = EarlyStopping(monitor='val_loss',\n",
    "                                       min_delta=0,\n",
    "                                       patience=15,\n",
    "                                       verbose=1,\n",
    "                                       mode='auto')\n",
    "\n",
    "modelcheckpoint_callback = ModelCheckpoint(filepath=experiment_name+'.hdf5',\n",
    "                                           save_best_only=True,\n",
    "                                           monitor='val_loss',\n",
    "                                           mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_dir = os.path.join(dir_path, \"fov_images\", \"saliency\")\n",
    "#videos = os.listdir(saliency_dir) \n",
    "#print(videos)\n",
    "\n",
    "path_to_sensor_data_train = os.path.join(dir_path, \"preprocessed_train\")\n",
    "videos = os.listdir(path_to_sensor_data_train)\n",
    "videos = videos\n",
    "print(videos)\n",
    "video_width = 3840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_generator = True\n",
    "if use_generator:\n",
    "    nb_epochs = 150\n",
    "    start = time.time()\n",
    "    \n",
    "    perc_train = 0.8\n",
    "    ind_max_train = int(np.round(len(videos) * perc_train))\n",
    "    file_names_train = videos[:ind_max_train]\n",
    "    file_names_val = videos[ind_max_train:]\n",
    "    #data = np.load(os.path.join(path_to_sensor_data_train, file_name))\n",
    "\n",
    "    train_gen = data_generator_head_seq2seq_reinject_output(path_to_sensor_data_train,\n",
    "                                    file_names_train,\n",
    "                                    delays_list,\n",
    "                                    n_max_delay,\n",
    "                                    n_lookback,\n",
    "                                    n_delay)\n",
    "    val_gen = data_generator_head_seq2seq_reinject_output(path_to_sensor_data_train,\n",
    "                                  file_names_val,\n",
    "                                  delays_list,\n",
    "                                  n_max_delay,\n",
    "                                  n_lookback,\n",
    "                                  n_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoder_input, decoder_input], Y_train = next(train_gen)\n",
    "\n",
    "fig=plt.figure(figsize=(18, 16), dpi= 80)\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(encoder_input[:,0,0], c='r')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(encoder_input[:,0,1], c='g')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(encoder_input[:,0,2], c='b')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_gen,\n",
    "                    steps_per_epoch=ind_max_train,\n",
    "                    epochs=nb_epochs,\n",
    "                    callbacks=[\n",
    "                               tensorboard_callback,\n",
    "                               earlystopping_callback,\n",
    "                               modelcheckpoint_callback],\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=len(videos) - ind_max_train)\n",
    "print(\"Time:\", time.time() - start, \"s = \",(time.time() - start)/60., \"min\")\n",
    "\n",
    "print(\"Training Time : \", time.time() - start, \"s = \", (time.time() - start)/60., \"min = \",\n",
    "      (time.time() - start)/3600., \"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['rmse'])\n",
    "plt.plot(history.history['val_rmse'])\n",
    "plt.title('model rmse')\n",
    "plt.ylabel('rmse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(Y1, Y2):\n",
    "   return np.mean(np.absolute(Y1 - Y2))\n",
    "\n",
    "def get_rmse(Y1, Y2):\n",
    "    return np.sqrt(np.mean(np.square(Y1 - Y2)))\n",
    "\n",
    "def get_smape(Y1, Y2):\n",
    "    return 100 * np.mean(np.absolute(Y1 - Y2) / (np.absolute(Y2) + np.absolute(Y1)))\n",
    "\n",
    "def get_mfe(Y_pred, Y_target):\n",
    "    return np.mean(Y_pred - Y_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance on validation data to improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(experiment_name+'.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_to_sensor_data_train = os.path.join(dir_path, \"preprocessed_train\")\n",
    "\n",
    "val_gen_pred = data_generator_head_seq2seq_reinject_output(path_to_sensor_data_train,\n",
    "                                         file_names_val,\n",
    "                                         delays_list,\n",
    "                                         n_max_delay,\n",
    "                                         n_lookback,\n",
    "                                         n_delay,\n",
    "                                         inference=True\n",
    "                                        )\n",
    "\n",
    "predictions_mae_val = np.zeros((len(file_names_val), 1+len_delay))\n",
    "predictions_rmse_val = np.zeros((len(file_names_val), 1+len_delay))\n",
    "predictions_smape_val = np.zeros((len(file_names_val), 1+len_delay))\n",
    "predictions_mfe_val = np.zeros((len(file_names_val), 1+len_delay))\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "start = time.time()\n",
    "print(\"Evaluating validation data...\")\n",
    "\n",
    "for [encoder_input, decoder_input], Y_val_abs in val_gen_pred:\n",
    "    #print(len(encoder_input))\n",
    "    #input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    Y_pred_diff = model.predict([encoder_input, decoder_input], verbose=0)\n",
    "    \n",
    "    # From normalized differences to absolute values\n",
    "    Y_pred = np.zeros(Y_pred_diff.shape)\n",
    "    for i in range(len_delay):\n",
    "        Y_pred[:, i] = Y_val_abs[:,0] + np.sum(Y_pred_diff[:, :i+1], axis=1) * MAX_DIFF\n",
    "        \n",
    "    Y_val_abs = Y_val_abs[:, 1:]\n",
    "\n",
    "    predictions_mae_val[count, 0] = get_mae(Y_pred, Y_val_abs)\n",
    "    predictions_rmse_val[count, 0] = get_rmse(Y_pred, Y_val_abs)\n",
    "    predictions_smape_val[count, 0] = get_smape(Y_pred, Y_val_abs)\n",
    "    predictions_mfe_val[count, 0] = get_mfe(Y_pred, Y_val_abs)\n",
    "    \n",
    "    #print(Y_pred.shape)\n",
    "    for ind_delay in range(0,len_delay):\n",
    "        Y_delay_pred = Y_pred[: ,ind_delay]\n",
    "        Y_delay_val = Y_val_abs[: ,ind_delay]\n",
    "        \n",
    "        predictions_mae_val[count, 1+ind_delay] = get_mae(Y_delay_pred, Y_delay_val)\n",
    "        predictions_rmse_val[count, 1+ind_delay] = get_rmse(Y_delay_pred, Y_delay_val)\n",
    "        predictions_smape_val[count, 1+ind_delay] = get_smape(Y_delay_pred, Y_delay_val)\n",
    "        predictions_mfe_val[count, 1+ind_delay] = get_mfe(Y_delay_pred, Y_delay_val)\n",
    "    \n",
    "    count += 1\n",
    "    if count == len(file_names_val):\n",
    "        break\n",
    "\n",
    "results_mae_val = np.mean(predictions_mae_val, axis=0)\n",
    "results_rmse_val = np.mean(predictions_rmse_val, axis=0)\n",
    "results_smape_val = np.mean(predictions_smape_val, axis=0)\n",
    "results_mfe_val = np.mean(predictions_mfe_val, axis=0)\n",
    "\n",
    "print(\"Evaluation Time : \", time.time() - start, \"s = \", (time.time() - start)/60., \"min = \",\n",
    "      (time.time() - start)/3600., \"h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"MAE\")\n",
    "print(\"Average mae:\", results_mae_val[0])\n",
    "for i, delay in enumerate(delays_list):\n",
    "    print(\"Delay\", delay, \"ms:\", results_mae_val[i+1])\n",
    "print()    \n",
    "print(\"RMSE\")\n",
    "print(\"Average rmse:\", results_rmse_val[0])\n",
    "for i, delay in enumerate(delays_list):\n",
    "    print(\"Delay\", delay, \"ms:\", results_rmse_val[i+1])\n",
    "print()    \n",
    "print(\"SMAPE\")\n",
    "print(\"Average smape:\", results_smape_val[0])\n",
    "for i, delay in enumerate(delays_list):\n",
    "    print(\"Delay\", delay, \"ms:\", results_smape_val[i+1])\n",
    "print()\n",
    "print(\"MFE\")\n",
    "print(\"Average mfe:\", results_mfe_val[0])\n",
    "for i, delay in enumerate(delays_list):\n",
    "    print(\"Delay\", delay, \"ms:\", results_mfe_val[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoder_input, decoder_input], Y_val = next(val_gen)\n",
    "print(encoder_input.shape, Y_val.shape)\n",
    "Y_pred = model.predict([encoder_input, decoder_input], verbose=0)\n",
    "\n",
    "fig=plt.figure(figsize=(18, 16), dpi= 80)\n",
    "plt.grid(True)\n",
    "plt.axvline(x=0, c=\"b\")\n",
    "x_axis_pred = np.concatenate((np.linspace(-lookback, 0, num=n_lookback), np.linspace(step_delay, delays_list[-1], num=len(delays_list))))\n",
    "time_sample = 700\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(x_axis_pred, np.concatenate((encoder_input[time_sample,:,0], Y_val[time_sample, :, 0])), label=\"ground truth\", c='r')\n",
    "plt.plot(x_axis_pred, np.concatenate((encoder_input[time_sample,:,0], Y_pred[time_sample, :, 0])), label=\"prediction\", c='g', marker=\"x\")\n",
    "plt.ylabel(\"x\")\n",
    "plt.xlabel(\"time (in ms)\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(x_axis_pred, np.concatenate((encoder_input[time_sample,:,1], Y_val[time_sample, :, 1])), label=\"ground truth\", c='r')\n",
    "plt.plot(x_axis_pred, np.concatenate((encoder_input[time_sample,:,1], Y_pred[time_sample, :, 1])), label=\"prediction\", c='g', marker=\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"time (in ms)\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(x_axis_pred, np.concatenate((encoder_input[time_sample,:,2], Y_val[time_sample, :, 2])), label=\"ground truth\", c='r')\n",
    "plt.plot(x_axis_pred, np.concatenate((encoder_input[time_sample,:,2], Y_pred[time_sample, :, 2])), label=\"prediction\", c='g', marker=\"x\")\n",
    "plt.ylabel(\"z\")\n",
    "plt.xlabel(\"time (in ms)\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
